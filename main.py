# -*- coding: utf-8 -*-
"""sreenivas-arvind-assgn2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QPSy7vxxt-Oc38Zk1YrmFvW6I2Afo1VG
"""

import numpy as np
import math
from numpy import genfromtxt
import re
my_data = genfromtxt('/content/features.csv', delimiter=',',dtype=None, encoding=None)
pos_words = open("/content/positive-words.txt", "r").read().splitlines()
neg_words=open("/content/negative-words.txt", "r").read().splitlines()
)

## First we define a class for Feature Extraction

class FeatureExtraction:
  def __init__(self):
    pass
  def count_positive(self):
    count=0
    for i in self.words:
      if i in pos_words:
        count+=1
    return count

  def count_negative(self):
    count=0
    for i in self.words:
      if i in neg_words:
        count+=1
    return count

  def check_no(self):
    if 'no' in self.words:
      return 1
    return 0

  def count_pronoun(self):
    count=0
    pronouns=["i", "me", "mine", "my", "you", "your", "yours", "we", "us", "ours"]
    for i in self.words:
      if i in pronouns:
        count+=1
    return count

  def check_exclaim(self):
    for i in self.words:
      if '!' in i:
        return 1
    return 0

  def count_words(self):
    return math.log(len(self.words))

  def extract_features(self,test_data):
    test_feature_dict={}
    for sent in test_data:
      string=re.sub(r'[^\w\s]', '',test_data[sent]).lower() #Removing punctuation and converting string to lower
      words= string.split()
      self.words=words
      pos_count=self.count_positive()
      neg_count=self.count_negative()
      no=self.check_no()
      pronoun_count=self.count_pronoun()
      exclaim=self.check_exclaim()
      word_count=self.count_words()
      test_feature_dict[sent]=[pos_count,neg_count,no,pronoun_count,exclaim,word_count,1]
    return test_feature_dict
## Defining a class for Logistic Regression
class LogisticRegression:
  def __init__(self) -> None:
      pass

  def test_dev_split(self,my_data):
    np.random.shuffle(my_data)
    train_size = int(0.8 * len(my_data))
    train_set=my_data[:train_size]
    dev_set=my_data[train_size:]
    return train_set, dev_set

  def extract_feature_vector(self,train_set):
    x=[]
    y=[]
    for i in range(len(train_set)):
      temp = list(train_set[i])[1:7]
      temp.append(1)
      x.append(temp)
      y.append(train_set[i][7])
    return np.array(x),np.array(y)

  def sigmoid(self,w,x):
    z=1/(1+np.exp(-1*(np.dot(w,x))))
    return z

  def gradient(self,w,X,Y):
    gradients=[]
    for i in range(len(X)):
      gradients.append([(self.sigmoid(w,X[i])-Y[i])*X[i]])
    return np.array(gradients,dtype=np.float128)

  def sgd(self,X,Y):
    w=np.array([0,0,0,0,0,0,1])
    a=0.1
    for i in range(200):
      gradients= self.gradient(w,X,Y)
      for j in range(len(gradients)):
        w=w-a*gradients[j]
    return w
  
  def predict(self,w,X):
    y_hat= np.round(self.sigmoid(w,X))
    if y_hat==0:
      return 'NEG'
    elif y_hat==1:
      return 'POS'

##Calculating weight##
train=LogisticRegression()
x_train,y_train=train.extract_feature_vector(my_data)
weights= train.sgd(x_train,y_train)

##Open the test data
test = open("/content/HW2-testset.txt", "r").read().splitlines()
test_data={}
for line in test:
  temp = line.split("\t")
  test_data[temp[0]]=temp[1]
fe = FeatureExtraction()
test_feature_dict=fe.extract_features(test_data)

##Export prediction to txt file
f = open("sreenivas-arvind-assgn2-out.txt", "w")
for id in test_feature_dict:
  st=id+"\t"+ train.predict(weights,test_feature_dict[id])
  f.write(st+"\n")
f.close()

